import json
import os
from typing import Optional

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

try:
    import openai
except ImportError:
    # openai might not be installed in offline environments. It's optional.
    openai = None

from dotenv import load_dotenv

# Load environment variables from .env file in the project root if present
load_dotenv(dotenv_path=os.path.join(os.path.dirname(__file__), "..", ".env"))

app = FastAPI()

# Allow all origins and methods for simplicity. In production you should restrict this.
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


class SuggestRequest(BaseModel):
    """
    Payload received from the browser extension.
    - email_body: The plain text of the incoming email.
    - author: String with the selected responder, e.g. "Lars-Ivar (Daglig leder, Hår1)".
    - context: Optional extra instructions for how the model should answer, e.g. "svar kort".
    """

    email_body: str
    author: Optional[str] = None
    context: Optional[str] = None

    # Optional template to prime the model. If provided, the backend will insert the
    # template text into the prompt so the model can follow a standard structure.
    template: Optional[str] = None
    # Optional tone instruction (e.g. Formell, Uformell, Kort, Høflig). Used to influence
    # the style of the generated answer.
    tone: Optional[str] = None


class SuggestResponse(BaseModel):
    """
    Response returned to the extension.
    - subject: Suggested subject line.
    - body: Suggested email body.
    """

    subject: str
    body: str


class RateRequest(BaseModel):
    """
    Payload received when a user rates a generated response.
    - email_body: Original incoming email content.
    - generated_response: The reply generated by the assistant (including signature).
    - rating: Integer from 1 to 5 provided by the end user.
    - author: Optional author string from the dropdown (e.g. "Bente (Distriktssjef, Hår1)").
    - template: Optional template name used when generating the reply.
    - tone: Optional tone selected by the user.
    """

    email_body: str
    generated_response: str
    rating: int
    author: Optional[str] = None
    template: Optional[str] = None
    tone: Optional[str] = None


def build_prompt(
    system_prompt: str,
    author: Optional[str],
    context: Optional[str],
    email_body: str,
    template_text: Optional[str] = None,
    tone: Optional[str] = None,
) -> list:
    """
    Construct the chat messages for the OpenAI API.
    The system prompt defines the general behaviour of the assistant. We then insert
    the author, template, tone and context before the email body. Each element is
    separated by blank lines to clearly delineate sections in the user message.
    """
    pieces: list[str] = []
    if author:
        pieces.append(f"Avsender: {author}")
    if template_text:
        # Include the full template text so the model can incorporate it.
        pieces.append(f"Mal: {template_text}")
    if tone:
        pieces.append(f"Tone: {tone}")
    if context:
        pieces.append(f"Instruksjon: {context}")
    pieces.append("Innkommende e‑post:")
    pieces.append(email_body)
    user_content = "\n\n".join(pieces)
    return [
        {"role": "system", "content": system_prompt},
        {
            "role": "user",
            "content": user_content,
        },
    ]


@app.post("/api/suggest", response_model=SuggestResponse)
async def suggest(request: SuggestRequest) -> SuggestResponse:
    """
    Generate a suggested reply based on the incoming email and optional metadata.
    If an OPENAI_API_KEY is available, we call OpenAI's chat completion endpoint.
    Otherwise, we return a simple placeholder reply.
    """
    # Read the system prompt from file. This defines tone and style.
    system_path = os.path.join(os.path.dirname(__file__), "..", "prompts", "system.txt")
    try:
        with open(system_path, encoding="utf-8") as f:
            system_prompt = f.read().strip()
    except FileNotFoundError:
        system_prompt = (
            "Du er en hjelpsom e‑postassistent for selskapet Hår1. "
            "Svar alltid høflig, profesjonelt og i en vennlig tone. "
            "Svar på norsk med god grammatikk."
        )

    # Load templates from JSON if available
    template_text = None
    if request.template:
        # Look up template text in prompts/templates.json
        templates_path = os.path.join(os.path.dirname(__file__), "..", "prompts", "templates.json")
        try:
            with open(templates_path, encoding="utf-8") as tf:
                templates = json.load(tf)
            template_text = templates.get(request.template, "")
        except Exception:
            template_text = ""

    # Build messages including template and tone
    messages = build_prompt(
        system_prompt,
        request.author,
        request.context,
        request.email_body,
        template_text=template_text,
        tone=request.tone,
    )

    # Check for API key
    api_key = os.getenv("OPENAI_API_KEY")
    model = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

    if api_key and openai is not None:
        try:
            client = openai.OpenAI(api_key=api_key)
            # Call the OpenAI chat completions API synchronously.  Some versions of the
            # `openai` Python library return a plain object that cannot be awaited.
            completion = client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=0.4,
            )
            content = completion.choices[0].message.content.strip()
            # Expecting the model to return a JSON object with subject and body
            try:
                parsed = json.loads(content)
                subject = parsed.get("subject", "").strip()
                body = parsed.get("body", "").strip()
                # Fallback if fields are missing
                if not subject or not body:
                    raise ValueError("Incomplete JSON from model")
            except Exception:
                # If the model response isn't valid JSON, treat it as the body and use a generic subject
                subject = "Svar"
                body = content

            # Remove any lines in the body that repeat the subject or include contact details.
            # We filter out:
            #  - lines starting with "Emne:" (case-insensitive)
            #  - lines that look like phone numbers (contain digits and '+' or the word 'tlf')
            #  - lines that contain an email address (the '@' symbol)
            filtered_lines = []
            # Normalize subject without prefixes for comparison
            norm_subject = subject.lower().replace("re:", "").replace("sv:", "").strip()
            for line in body.splitlines():
                # Skip empty lines at this point; we'll add them back later
                stripped = line.strip()
                if not stripped:
                    filtered_lines.append(line)
                    continue
                lower_line = stripped.lower()
                # Skip lines starting with "emne:" or repeating the subject
                if lower_line.startswith("emne:"):
                    continue
                # If the line equals the subject (case-insensitive), skip it
                if norm_subject and lower_line.startswith(norm_subject):
                    continue
                # Skip phone number or contact details
                # Check if the line contains digits and either '+' or the word 'tlf'
                import re
                if re.search(r"(\btlf\b|\btelefon\b)", lower_line) and any(ch.isdigit() for ch in stripped):
                    continue
                # Skip lines with an '@' symbol (likely an email address)
                if '@' in stripped:
                    continue
                filtered_lines.append(line)
            body = "\n".join(filtered_lines).strip()
        except Exception as e:
            # In case of API errors, log and return a fallback
            print(f"Error calling OpenAI: {e}")
            subject = "Svar"
            body = (
                "Beklager, vi klarte ikke å hente et forslag akkurat nå. "
                "Prøv igjen senere eller kontakt systemadministrator."
            )
    else:
        # No API key or openai library available → return placeholder
        subject = "Svar"
        body = (
            "Dette er et testsvar generert uten tilgang til OpenAI. "
            "Installér openai‑biblioteket og sett OPENAI_API_KEY i .env for ekte svar."
        )

    # Append a signature using the provided author if available. To avoid duplicate
    # signaturer legger vi den bare til hvis ikke "vennlig hilsen" allerede finnes i svaret.
    if request.author:
        # Check case-insensitive to see if the body already contains a sign-off.
        lower_body = body.lower()
        if "med vennlig hilsen" not in lower_body and "vennlig hilsen" not in lower_body:
            body = body.strip() + "\n\nMed vennlig hilsen,\n" + request.author

    return SuggestResponse(subject=subject, body=body)


@app.post("/api/rate")
async def rate(request: RateRequest) -> dict:
    """
    Receive a rating for a generated response and persist it for later analysis or model improvement.
    The ratings are appended as JSON objects to a local file. This endpoint returns a simple
    acknowledgement and does not influence the current reply generation.
    """
    try:
        ratings_path = os.path.join(os.path.dirname(__file__), "..", "ratings.jsonl")
        record = request.dict()
        # Append the rating as a single line of JSON
        with open(ratings_path, "a", encoding="utf-8") as f:
            f.write(json.dumps(record, ensure_ascii=False) + "\n")
        return {"status": "ok"}
    except Exception as e:
        print(f"Error storing rating: {e}")
        return {"status": "error", "detail": str(e)}